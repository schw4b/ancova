---
title: "17-DePascalis"
author: "Simon Schwab, Audrey Yeo"
date: "11/13/2019"
output: html_document
---

# Reference
DePascalis. (2017). Serotonin and dopamine transporter PET changes in the premotor phase of LRRK2 parkinsonism: cross-sectional studies. *Lancet Neurology*, 16(5), 351–359. https://doi.org/10.1038/srep41588

We first load the appropriate packages
```{r, eval=TRUE, echo=FALSE, include = FALSE}
#Setting up libraries
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(foreign)
library(readxl)
library(readstata13)
library(car) # for levene's test
library(effects)# for adjusted means
library(ggplot2) # for graphs
library(multcomp) #for post hoc test
library(pastecs)# for descriptive statistics
library(reshape)
library(effects)# for effect command
library(ggplot2)
library(beeswarm)
library(tidyr)
```

#Paper's results section

The outcome of interest in the ANCOVA is "N1/P2 complex"
The independant variables are Emotion (3 levels), Auditory Intensity (five levels), Recording side (three levels) and a Covariate.

```{r, eval=TRUE, echo=FALSE, include = FALSE}

# A similar ANCOVA performed on the N1/P2 slope scores found a highly significant main effect for the BIS, F1,37=13.12, p=0.0009, η2=0.35, indicating lower slopes for high-BIS individuals compared to low-BIS participants (Fig. 2c).

Fvalue =  13.12
df1 = 1
df2 = 37
pvalue = 0.0009
estimates = as.data.frame(cbind(F, df1, df2, pvalue))
rownames(estimates) = c("Study")
estimates
```

```{r, include = TRUE, echo = FALSE, eval = TRUE, tidy = TRUE}
level1 = 3
level2 = 5
level3 = 3
combo <- level1*level2*level3 # possible number of DV based on counts of IV and each of their levels, = 45
```
# Reading data
Data is loaded, reshaped if necessary, and factors are specified.
```{r, include = TRUE, echo = FALSE, eval = TRUE, tidy = TRUE}
data = read_excel("../results/data/17-DePascalis/BIS_cov_N1-P2peak_amplitude_r.xlsx", skip = 4)
names(data)
dim(data)
# correcting typo
colnames(data)[2] <- "Subject"


#creating a long form data set, first pull columns and set as class data.frame, then name columns #39 * 15 different levels is 353
EmotionIV <- as.data.frame(c(rep("Neutral", 585), rep("Negative", 585), rep("Positive", 585)))
colnames(EmotionIV) <- "EmotionIV"
dim(EmotionIV)
head(EmotionIV)

IntensityIV <- as.data.frame(c(rep("One", 351), rep("Two", 351), rep("Three", 351), rep("Four", 351), rep("Five", 351)))
colnames(IntensityIV) <- "IntensityIV"
dim(IntensityIV)

ElectrodeIV <- as.data.frame(c(rep("ElectrodeOne", 585), rep("ElectrodeTwo", 585), rep("ElectrodeThree", 585)))
colnames(ElectrodeIV) <- "ElectrodeIV"
dim(ElectrodeIV)


COV <- as.data.frame(rep(data$RST_BIS[1:39], 45))
colnames(COV) <- "COV"
dim(COV)
names(data)

# DV <- c(data[1:40,3], data[1:39,4], data[1:39,5], data[1:39,6], data[1:39,7], data[1:39,8], data[1:39,9], data[1:39, 10], data[1:39, 11], data[1:39, 12], data[1:39, 13], data[1:39, 14])
DV00 <- gather(data, "DVcat", "DV", -Subject, -Oss, -RST_BIS, -`...48`) 
DV0 <- as.data.frame(DV00[,-c(3:5)]) # we dont need this
names(data)
names(DV00)
names(DV0)
boom <- cbind(DV0, COV, IntensityIV, EmotionIV, ElectrodeIV)
View(boom)
data <- boom
names(data)
View(data)
head()
```
Running an initial ANCOVA

# Interpreting the main effects of ANCOVA
Main effects of ANCOVA
```{r, include = TRUE, echo = FALSE, eval = TRUE, tidy = TRUE}
#contrasts(data$IV)<-cbind(c(-2,1,1), c(0,-1,1))
ancovaModel<-aov(DV ~ COV + EmotionIV*IntensityIV*ElectrodeIV,  data = data) # there is evidence of significance that COV impacts on DV, residuals is less than the belowmodel
summary(ancovaModel)
Anova(ancovaModel, type = "3")
Error(Subject/(EmotionIV*IntensityIV*ElectrodeIV))
ancovaModel<-aov(DV ~ COV + EmotionIV, data = data) # there is evidence of significance that COV impacts on DV, larger residuals than above model

lm_ancova <- lm(DV ~ COV + EmotionIV + IntensityIV + ElectrodeIV + (1|data$Oss), data = data)
summary(lm_ancova)
Anova(lm_ancova, type="III")

Fvalue =  13.12
df1 = 1
df2 = 37
pvalue = 0.0009
estimates = as.data.frame(cbind(F, df1, df2, pvalue))
rownames(estimates) = c("Study")
estimates
```
<p align="left">
  <b> Definitions </b>
</p>  
<p align="left">
- The rationale for ANCOVA is two folds:
  1. Reduce within-group error variance
  2. Eliminate confounders
- An ANOVA is a type of linear regression model, an ANCOVA is an ANOVA, which accounts for potential confounders which are usually continuous variables
- An ANCOVA model is the analysis of covariance where the variance of the outcome is explained by discrete variable (Independant variable) and covariates which are continuous variables.
</p>

Checking Assumptions 

## Motivation

<b>  </b> 
<p align="left">
- Initial one-way ANOVA show that there is no evidence of significant relationship between dose and libido, motivates to evaluate its underlying covariances to answer :
- What is the variance explained by three doses of Viagra on Libido?
- And what is the variance explained by Partner Libido on Libido. 
</p>
```{r, include = TRUE, echo = TRUE, eval = TRUE, tidy = TRUE}
mod1 <- aov(DV ~ EmotionIV, data = data)
mod2 <- aov(DV ~ IntensityIV, data = data)
mod3 <- aov(DV ~ ElectrodeIV, data = data)
c(summary(mod1$fitted.values,summary(mod2$coefficients),summary(mod3$coefficients))

mod1$coefficients

```
## Explore Data
<p align="left">
- Boxplot shows: Does different doses produce different outcomes
</p>
```{r, echo= TRUE, include = TRUE, eval = TRUE, tidy = TRUE}
#IV : Emotion
par(mfrow=c(1,2))
beeswarm(DV~EmotionIV, data= data, main = "Emotion vs Outcome", pch = 16, col = rainbow(8))
boxplot(DV~EmotionIV, data= data, outline = FALSE, main = " ", add= TRUE) 
par(mfrow=c(1,2))
beeswarm(COV~EmotionIV, data= data, pch = 16, col = rainbow(8), main = "Emotion vs Covariate")
boxplot(COV ~ EmotionIV, data = data, outline = FALSE, main = " ", add = TRUE) 

#IV : Intensity
par(mfrow=c(1,2))
beeswarm(DV~IntensityIV, data= data, main = "Emotion vs Outcome", pch = 16, col = rainbow(8))
boxplot(DV~IntensityIV, data= data, outline = FALSE, main = " ", add= TRUE) 
par(mfrow=c(1,2))
beeswarm(COV~IntensityIV, data= data, pch = 16, col = rainbow(8), main = "Emotion vs Covariate")
boxplot(COV ~ IntensityIV, data = data, outline = FALSE, main = " ", add = TRUE) 
#IV : Electrode
par(mfrow=c(1,2))
beeswarm(DV~ElectrodeIV, data= data, main = "Emotion vs Outcome", pch = 16, col = rainbow(8))
boxplot(DV~ElectrodeIV, data= data, outline = FALSE, main = " ", add= TRUE) 
par(mfrow=c(1,2))
beeswarm(COV~ElectrodeIV, data= data, pch = 16, col = rainbow(8), main = "Emotion vs Covariate")
boxplot(COV ~ ElectrodeIV, data = data, outline = FALSE, main = " ", add = TRUE) 
```
## Explore Data : Descriptives
<p align="left">
- Descriptive Statistics
</p>
```{r, include = TRUE, echo = TRUE, eval = TRUE, tidy = TRUE}
by(data$DV, data$EmotionIV, stat.desc)
by(data$DV, data$EmotionIV, stat.desc)
```

## Explore Data : Graphical analysis for homogeneity of regression slopes
<p align="left">
- Say we want to know the overall relationship between Viagra and Partner libido, ignoring which dose groups the data points belong to, we therefore assume that the relationship between dose group and partner libido is constant across all doses. If the latter is not true, then the overall relationship between Viagra and Partner libido is inaccurate.
- there is homogeneity of regression slopes for Placebo and Lower doses
- there is no homogeneity of regression slopes for Placebo and High dose
- That's ok because there are situations where you might actually expect regression slopes to differ across groups and that this is, in itself, an interesting hypothesis. 
</p>

## Graphical Anaylsis for homogeneity of regression slopes

```{r, include = TRUE, echo = FALSE, eval = TRUE, tidy = TRUE}

data %>% ggplot() +
+   geom_jitter(aes(COV, DV, colour = factor(EmotionIV))) +
+   geom_smooth(method = lm)

ggplot(data, aes(y = DV, x = EmotionIV, group = factor(EmotionIV), colour = factor(EmotionIV))) +  geom_jitter(aes(colour = factor(EmotionIV))) + geom_smooth(method = lm)
```

## Assumption 1 : Homogeneity of variance
<p align="left">
- Levene's Test: Are the variances between levels on outcome very similar ?
- A good double-check of Levene’s test is to look at the highest and lowest variances. For our levels we have standard deviations of .
</p>
```{r, include = TRUE, echo = TRUE, eval = TRUE, tidy = TRUE}
leveneTest(data$DV, data$EmotionIV, center = median)
leveneTest(data$DV, data$IntensityIV, center = median)
leveneTest(data$DV, data$ElectrodeIV, center = median)
```
## Assumption 2 : Check that the covariate and any independent variables are independent

<p align="left">
- We run an ANOVA to find out if the covariance independant to each of the IV levels? 
- The summary results show that on different levels for each IV, there is no evidence of significant association to N1/P2 complex.
</p>
```{r, eval = TRUE, echo = TRUE}
checkIndependenceModel1<-aov(COV ~ EmotionIV, data = data) 
checkIndependenceModel2<-aov(COV ~ IntensityIV, data = data)
checkIndependenceModel3<-aov(COV ~ ElectrodeIV, data = data)
summary(checkIndependenceModel1)
summary(checkIndependenceModel2)
summary(checkIndependenceModel3)
```
## Residuals vs Fitted : Testing for Homogeneity of Variance
<p align="left">
- The residuals for fitted value are similar to zero, assumption for homogeneity of variance held.
</p>
```{r, include = TRUE, echo = FALSE, eval = TRUE, tidy= TRUE, fig.width = 6, fig.height = 5}
plot(ancovaModel, which = 1)
```
## QQ plots
<p align="left">
- Residuals are normally distributed
</p>
```{r, include = TRUE, echo = FALSE, eval = TRUE, tidy =TRUE, fig.width = 4, fig.height = 5}
plot(ancovaModel, which = 2)
```
## Post Hoc Tests 
<p align="left">
- A Tukey-Ascombe test is performed via a general linear hypotheses function from library(multcomp).
- It is used for a pairwise comparison t test between doses for between groups differences
- In other words: we want to test differences between the adjusted means.
- In this case, the differences between IV levels can be compared with evidence of significance.
- In this method, we are restricted to the Tukey and the Dunnett method.
</p>
```{r, include = TRUE, echo = TRUE, eval = TRUE}
postHocs<-glht(ancovaModel, linfct = mcp(ElectrodeIV = "Tukey"))
summary(postHocs)
confint(postHocs)
```
## Going back to Basic Assumptions : Homogeneity of Regression Slopes
<p align="left">
There is a positive relationship between all IV and Covariate.
</p>
```{r, include = TRUE, echo = TRUE, eval = TRUE}
#IVA <- c(EmotionIV, IntensityIV, ElectrodeIV)
# IVA[1]
# for (i in 1:3){assign(paste0("hoRs",i, aov(DV ~ COV*IV[i], data = data)))} 

hoRS1<-aov(DV ~ COV*EmotionIV, data = data)
hoRS2<-aov(DV ~ COV*IntensityIV, data = data)
hoRS2<-aov(DV ~ COV*ElectrodeIV, data = data)

hoRS1<-update(ancovaModel, .~. + COV:EmotionIV)
hoRS2<-update(ancovaModel, .~. + COV:IntensityIV)
hoR3S<-update(ancovaModel, .~. + COV:ElectrodeIV)

summary(hoRS1) 
summary(hoRS2)
summary(hoR3S)

df01 <- Anova(hoRS1, type="III")
df02 <- Anova(hoRS1, type="III")
df03 <- Anova(hoRS1, type="III")

df <- as.data.frame(c(df01[3, 3:4],df02[3, 3:4],df03[3, 3:4]))
```

## Creating a data frame 
<p align="left">
- 
</p>
```{r}
reanalysis = cbind(FvalueR, df1R, df2R, pvalueR)
rownames(reanalysis) = c("Reanalysis")
estimates = rbind(estimates, reanalysis)
```

